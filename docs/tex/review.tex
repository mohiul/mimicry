%Review Chapter
\chapter{Review}

\begin{quote}
\textsl{``The theory of evolution by cumulative natural selection is the only theory we know of that is in principle capable of explaining the existence of organized complexity" - Richard Dawkins \cite{dawkins1996}}
\end{quote}

\section{Introduction}

\section{Evolutionary Computation}

\textsl{``The fundamental metaphor of evolutionary computing relates this powerful natural evolution to a particular style of problem solving - that of trial and error" - Eiben \cite{eiben2003}}

\subsection{History}

\paragraph{Turing(1948)}
Ideas for evolutionary computation initiated from Alan Turing from his 1948 report titled \textsl{``Intelligent Machinery"} where the expression of \textsl{``genetical or evolutionary search"}  was used \cite{turing1948}. He suggested a range of ideas for systems which could be said to modify their own programs. 

\paragraph{Bremermann(1962)}
Bremermann was the first to apply the concept of biological evolution to execute computer experiments for solving optimization problems \cite{bremermann1962}. He was the first to consider the problem of minimizing a real-valued fitness function. He selected very simple functions to optimize in order to provide a more tractable analysis of the evolutionary process.

\paragraph{Rechenberg(1964)}
Rechenberg's contribution is considered mostly in providing Evolutionary Strategies. He invented a highly influential set of optimization method which were successfully applied to challenging problems such as aerodynamic wing design. \cite{rechenberg1973}

\paragraph{L. Fogel, Owens and Walsh (1965)}
A seminal work that merged the fields of evolutionary computation and computational intelligence was by Fogel, Owens and Walsh in \textsl{``Artificial Intelligence through a simulation of evolution"} \cite{fogel1966}. In this book, evolutionary process was applied to finite state automata to predict symbol strings generated from Markov processes and non-stationary time series. Evolutionary prediction of such kind was motivated by the concept that prediction is a keystone to intelligent behavior (defined in terms of adaptive behavior, in that the intelligent organism must anticipate events in order to adapt behavior in light of a goal). 

\paragraph{Holland(1975)}
Perhaps the most significant work in terms of applications in the field of evolutionary computation comes from the inventor of genetic algorithms, John H. Holland. His ground breaking book \textsl{``Adaptation in natural and artificial systems"} \cite{holland1975} is where he developed \textit{The Schema Theorem} which is the foundation for explanation of the power of Genetic Algorithms.

\paragraph{Koza(1992)}
Koza's invention is the idea of Genetic Programming, which is an automated method for creating a working computer program from a high level statement of a problem. Starting from a high-level statement of \textsl{``what needs to be done"} it searches through all possible permutation of steps and finds the optimum solution through evolutionary methods \cite{koza1992}.

Contemporary terminology denotes the fields of \textbf{Evolutionary Strategy}, \textbf{Evolutionary Programming}, \textbf{Genetic Algorithm} and \textbf{Genetic Programming} to be under one umbrella termed as \textbf{Evolutionary Computation} while the algorithms are called \textbf{Evolutionary Algorithms}.

\subsection{Evolutionary Algorithms}
Algorithms which are inspired by the strategy of \textit{survival of the fittest} from evolutionary biology, and uses different methods to optimize mathematical expressions which are used to evaluate a pool of population of solutions over generation, can be defined as evolutionary algorithms. There are many different forms of evolutionary algorithm. All of which can be generalized to follow their pattern from natural selection. The mathematical expression, also termed as \textbf{fitness function} is used to evaluate the fitness of each individual from the set of existing solution space. An individual or a solution which provides higher output from the fitness function is considered as more fit to survive in the environment. So given a problem the algorithm initializes the environment with a random set of population or solutions. Then it uses the fitness function to select a better set of solutions from the existing once. After that different operators of \textbf{mutation} and \textbf{recombination} are applied to the selected set of solution to come up with a new generation of solution set born from the existing ones. Again the fitness function is applied to the current set of population to come up with a better set and this process iterates until the evaluation from the fitness function is satisfactory to give the best set of solutions.

According to Eiben \cite{eiben2003} this process has two fundamental forces that form the basis of evolutionary systems:

\begin{itemize}
	\item \textsl{``Variation operators (recombination and mutation) creates the necessary diversity and thereby facilitate novelty."}
	\item \textsl{``Selection acts as a force pushing quality."}
\end{itemize}

Important components of evolutionary algorithms are

\paragraph{Representation (Individuals or Solution Space)}
Evolutionary Algorithms(EA) are considered as robust problem solvers as it provides evenly good performance over a wide range of problems. To apply evolutionary algorithm to this wide range the most important part is representation of the solution space. In EA representation is analogous to the complex pathway that exits between \textbf{genotype} and \textbf{phenotype} of a biological organism.

\paragraph{Evaluation Function (Fitness Function)}
This is the function with which the solution is evaluated. The outcome of applying evolutionary algorithm to the problem depends on this function. It is defined to evaluate each of the solutions of the problem. In biology evaluation function is analogous to the decision of survival of any species in an environment. 

\paragraph{Population}
The population is the solution set of the problem over which EA will be applied. It is literally analogous to the same meaning in biology. The diversity of the population is very important. If the initial random population of solutions are diverse then there is more possibility of reaching an optimal solution space very quickly, and it also avoids reaching local optimum instead of the global optimum.

\paragraph{Variation operators, recombination and mutation}
Considering arity (number of object as input) variation operators are divided into two kinds. The mutation operator accepts only one operand. The process of mutation is similar to the way it happens in biology. It is a stochastic process, meaning, its output the child depends on the outcomes of a series of random choices. The operator is responsible for causing a random unbiased change. Mutation has very different roles in different fields of EC, for example in Genetic Programming it is not used at all, while in genetic algorithms it is a very pivotal process as it provides fresh blood to the existing set of solutions. Getting a new mutated child is like stepping into a new solution space outside of the ones which already exist in the parent pool. A recombination operator is responsible for merging two parent genotypes into one or two offspring genotypes. It is also a stochastic process depending on the choice of the parts of the parent individuals. Recombination operators with high arity (using more than two parent) are mathematically possible and easy to implement but does not have any biological equivalent. According to Eiben \cite{eiben2003} \textsl{``the principle behind recombination is simple - by mating two individuals with different but desirable features, we can produce an offspring that combines both of those features."} It is important that variation operators are defined based on the representation of the problem under consideration. 

\subsection{Genetic Algorithm}
Genetic Algorithms(GA) have the most wide set of applications. It was first conceived by John H. Holland for studying adaptive behavior as in \textit{Adaptation in natural and artificial systems} \cite{holland1975}. They are mainly considered as function optimizers. In general GA have many diverse representation schemes considering the solution set of the problem. Depending on the problem scenario an appropriate representation could be Binary, Grey Code, Integer, Real-Valued, Floating-point or Permutation based. 

Using GA for a binary representation mutation can be single point or multiple point, where a random location is selected from the binary genome and the bit is flipped. For integer representation random resetting is used instead of bit flipping. Creep mutation is another scheme which was designed for ordinal attributes and works by adding a small (positive or negative) value to each gene with a random probability. For a real-valued or floating-point mutation none of the above strategy is applicable. As for this case mutation is applied to a random gene maintaining a certain range of value within an upper and a lower bound and using a standard for randomization, such as Uniform, Gaussian or Cauchy distribution. For permutation representation, swap mutation is a strategy used by simply swapping the location of two randomly selected genes. Insert mutation is another strategy where a random gene is selected and inserted to a random location in the genome, causing the other genes to move a single space. In scramble mutation, location of a collection of randomly selected genes are scrambled, while in inversion mutation serialized location of a set of genes are inverted. 

GA also have many different recombination operators for each representation. For binary and integer representation one-point crossover and \textit{N}-point-crossover are the most frequently used. These two operators work by dividing the parent genome at one or multiple random points and combining them to create an offspring. Uniform-crossover \cite{sywerda1989} is another method which works by treating each gene independently and making a random choice at to which parent it should inherit from. Recombination for floating-point representation can use the same operators like binary and integer, and when it does it is termed as discreet recombination. Another type is intermediate or arithmetic recombination where the offspring do not just receive a part of their parent genome but instead their genomes are derived from their parent using an arithmetic formula. Permutation representation has many interesting recombination operators, out of which partially mapped crossover was first proposed by Goldsberg and Lingle \cite{goldberg1985} for the traveling salesman problem and since then it has become one of the most widely used operators for adjacency type problems. Other useful operators for permutation representation are Edge crossover, Order crossover and Cycle crossover, where their name provides more or less an appropriate description of their operation.

In regards to parent selection the most commonly used process by GA is fitness proportion selection, where the selection probability of a parent depends on the absolute fitness value of the individual compared to the absolute fitness values of the rest of the population. A fitness value is evaluated from the evaluation or the fitness function. Introduced by Holland \cite{holland1975} this procedure has a few problems. Premature convergence being one where individuals that are a lot better than the rest take over the entire population. Also when fitness values are all very close there is almost no selection pressure in evolution of the fittest. Inspired by the observed drawbacks of fitness proportion selection a method was proposed by Baker \cite{baker1987} termed as Ranking selection. This procedure preserves a constant selection pressure by sorting the population on the basis on fitness, and then allocating selection probabilities to individuals according to their rank. Both of the above mentioned selection procedures requires knowledge of the entire population. But when the population size is very large Tournament selection is an effective process. In this case a randomized pre-selection is done over the large population and then they are ranked according to their fitness value and selected as parent. 

Genetic Algorithms are one of the most effective strategy used in the field of evolutionary computation to solve optimization problems. Then again there are limitations. When the solution set of a problem do not have a gnomic representation, genetic algorithms cannot play any role in improving it. So the set of optimization problems to which GA can be applied is not universal.

\subsection{Evolutionary Strategies}
The key important property of the set of algorithms termed as ``Evolutionary Strategy" is \textbf{self-adaptation} of strategy parameters. The  parameters of Evolutionary Algorithm are included in the chromosomes and they co-evolve with the solution set while running the algorithm. To summarize these set of algorithms, they usually have real-valued vectors, their recombination process is discrete or intermediary, their mutation process uses Gaussian perturbation while parent selection is uniform random. In terms of their attribute feature they are fast and good optimizer for real-valued optimization.

\subsection{Evolutionary Programming}
The primary objective of evolutionary programming was to generate artificial intelligence by simulating evolution as a learning process \cite{fogel1966}. Capability of a system to adapt its behavior to meet some specified goal in the environment was considered as intelligence. Fogel used finite state machines as predictors and evolved them. Usually representation for evolutionary programming is with real-valued vectors. Its parent selection is deterministic, where each parent creates one offspring via mutation. There is no recombination operator for evolutionary programming. Mutation is applied with Gaussian perturbation. While survivor selection is probabilistic. 

\subsection{Genetic Programming}
Genetic programming is typically applied to machine learning tasks such as prediction and classification. Its attribute feature behaves similar to neural network and usually has huge populations of solution combination. The algorithm itself is a very slow process. These sets of algorithms use non-linear chromosomes such as trees and graphs. Mutation is mostly avoided for genetic programming. Recombination operators work by exchanging subtrees. Mutation if applied will be a random changing process in the tree. Parent selection process is usually fitness proportional while the survivor selection process is usually replacement of generations. From a technical point of view, genetic programming is simply a variant of genetic algorithm working with a different data structure: the chromosomes are trees. 

\section{Artificial Life}
As Artificial Intelligence is the field of computer science where scientists take concepts from psychology and implement into computer science. In contrast to that in Artificial Life scientist take concepts from Biology, specially Evolutionary Biology and genetics and implement into computer science. 

Christopher G. Langton is considered as one of the founders of the filed of Artificial Life. He invented the term in the late 1980's when he organized the first ``International Conference on the Synthesis and Simulation of Living Systems" at the Los Alamos National Laboratory in 1987.

In defining Artificial Life Christopher G. Langton states the following,

\begin{quote}
\textsl{`` `Art' + `Life' = Artificial Life: Life made by Man rather than by Nature. Our technological capabilities have brought us to the point where we are on the verge of creating `living' artifacts. The field of Artificial Life is devoted to studying the scientific, technological, artistic, philosophical, and social implications of such an accomplishment." - Christopher G. Langton}
\end{quote}

%\section{History}

%\paragraph{Jon Von Neumann}

%\paragraph{Tierra}

%\paragraph{Avida}

The field of Artificial Life (AL) has been described by Taylor as a tool for biological inquiry \cite{taylor1993}. While providing a brief survey over different AL models he talks about \textbf{Wetware systems} which work at the molecular level, the \textbf{Software systems} which work at the cellular level and the \textbf{Hardware systems} which works at the organism level.

%Describe Wetware, Software and Hardware systems of artificial life. 

\subsection{Complex Adaptive System}

\subsection{Echo}
Echo is a gedanken experiment rather than a precise simulation.

\subsubsection{Criteria}
Echo has been constructed on a certain set of criteria. The following is a short summary on it extracted from \cite{holland1996}.

\begin{itemize}
	\item Simplicity is considered as the first and foremost criteria. Instead of emulating a real system Echo is more of a thought experiment. Simplicity is attained by carefully constraining agent interaction and also giving the agents only a primitive internal model. 
	\item Actions and interaction of each agent in echo has been designed to be part of a wide range of \textsl{CAS} setting, while mobility is also part of a wide range of geographical setting. Input to the environment which are considered as stimuli or resource can also be diversified. 
	\item Fitness of each of the agents is an evolving criteria. Instead of considering fitness as an external exogenous factor, it should be dependent on the context provided by the site and other agents. Instead of being a constant value it should evolve along with the system. 
	\item ``The primitive mechanisms in Echo should have ready counter parts in all \textsl{CAS}. Interpretation of results from the Echo model should be direct and ready-made. As simulation is nothing but manipulation of numbers and symbols, it is always possible to make fanciful and deceiving interpretation of them, taking the opportunity to prove one's point. So by applying primitive mechanism for interpretation it is possible to avoid misinterpretation. 
	\item 
	\item 
\end{itemize}

\subsubsection{Organization}

\subsubsection{Agents}
Individual agents in echo


\subsubsection{Replication}

\subsubsection{Interactions}
\paragraph{Combat}
\paragraph{Trading}
\paragraph{Mating}
\subsubsection{Results}



\paragraph{Criteria}



\section{Cellular Automata}

\section{Conclusion}